(function(h,r){(function(g,h){var f=g.module("warrApp",["ngRoute","ngAria","warrData"]);f.constant("appVersion","1475859133-04ab17c");(function(f,c,g){var e={};c.constant("controllerBuilder",{build:function(b,a){var d=a+"Controller";e[a]||(b.register(d,["$scope","$sce","$routeParams","data","warrStore","appVersion",function(b,d,e,c,f,n){b.html=d.trustAsHtml;b.params=e;b.data=c;b.store=f(a);b.appVersion=n}]),e[a]=!0);return d}})})(g,f);(function(f,c,g){c.config(["$routeProvider","$controllerProvider",
"controllerBuilder","data",function(e,b,a,d){for(var l in d.pages){var c=d.pages[l];e.when(c.route,{controller:a.build(b,l),templateUrl:c.view,pagedata:c})}e.otherwise({redirectTo:"/"})}])})(g,f);(function(f,c,g){c.config(["$controllerProvider","controllerBuilder",function(e,b){b.build(e,"index")}])})(g,f);(function(f,c,g){function e(a){var d=a.match(/^\s*(\d\d\d\d)(-(\d\d)(-(\d\d))?)?\s*$/);if(!d||!d[1]||!d[3])return a;a=b[d[3]-1];return d[5]?a+" "+d[5].replace(/^0+/,"")+", "+d[1]:a+" "+d[1]}var b=
"January February March April May June July August September October November December".split(" ");c.directive("warrDateRange",[function(){return{restrict:"A",scope:{start:"=",end:"="},controller:["$scope",function(a){a.datefmt=e}],templateUrl:"daterange"}}])})(g,f);(function(f,c,g){c.directive("warrDefault",["$parse",function(e){return{restrict:"A",link:function(b,a,d){var c=e(d.ngModel),f=e(d.warrDefault);b.$watch(function(){return f(b)},function(){c.assign&&!c(b)&&c.assign(b,f(b))},1)}}}])})(g,
f);(function(f,c,g){c.directive("warrParas",[function(){function e(b,a,d,c){if(b)if(b.constructor===Array)for(var f=0;f<b.length;f++)e(b[f],a,d,c);else if(b.html)a[a.length]=b.html;else{b=""+b;if((f=b.match(/[^\r\n]+/g))&&1<f.length)return e(f,a,d,c);"<"==b.substr(0,1)&&">"==b.substr(-1)?a[a.length]=b:(d.text(b),a[a.length]="<"+c+">",a[a.length]=d.html(),a[a.length]="</"+c+">")}}return{restrict:"A",scope:{warrParas:"=",tag:"="},link:function(b,a,d){d=[];var c=f.element("<p/>");e(b.warrParas,d,c,b.tag||
"p");a.html(d.join(""))}}}])})(g,f);(function(f,c,g){c.directive("warrSortFilterBox",["warrStore",function(e){var b={"-start":"Most Recently Started","-end":"Most Recently Ended","-started":"Most Recently Started","-ended":"Most Recently Ended","-date":"Most Recently Published","+org":"Alphabetical by Organization","+title":"Alphabetical By Title","+name":"Alphabetical By Name"};return{restrict:"A",scope:{name:"=warrSortFilterBox",sortOptionsRaw:"=sortOptions",sort:"=",filter:"="},templateUrl:"sortfilterbox",
link:function(a){a.store=e(a.name);a.$watchCollection(function(){return a.sortOptionsRaw},function(){a.sortOptions=[];for(var d=0;d<a.sortOptionsRaw.length;d++)a.sortOptions.push({i:a.sortOptionsRaw[d],n:b[a.sortOptionsRaw[d]]})});a.$watch(function(){return a.store},function(){a.sort=a.store.sort;a.filter=a.store.filter},1)}}}])})(g,f);(function(f,c,g){c.filter("warrLinkUp",[function(){return function(e){if(!e)return e;for(var b,a=0;a<e.length;a++){var d=e[a];d.prev=function(){var a=b;return function(){return a}}();
d.next=function(){};b&&(b.next=function(){var a=d;return function(){return a}}());b=d}return e}}])})(g,f);(function(f,c,g){c.filter("warrValues",[function(){return function(e){var b=[],a;for(a in e)e.hasOwnProperty(a)&&(b[b.length]=e[a]);return b}}])})(g,f);(function(f,c,g){c.run(["$rootScope","$window","warrStore","$timeout",function(e,b,a,d){function c(){try{k.swapCache()}catch(a){}d(function(){b.location.reload()},0)}function f(){e.$apply(function(){m.time=Date.now()});2E3>Date.now()-q?c():d(function(){var a=
Date.now();5E3>a-n||(n=a,confirm("Website has been updated.  Reload to display the latest content?")&&c())},0)}function g(){k.status==k.UPDATEREADY&&f();var a="UNCACHED",b;for(b in p)k.status==k[b]&&(a=b);e.offlineStatusCode!=a&&e.$apply(function(){e.offlineStatusCode=a;e.offlineStatusText=p[a]||a})}var k=b.applicationCache;if(k){var q=Date.now(),n=0,m=a("appCache");m.time=m.time||Date.now();var p={UNCACHED:"Offline Not Supported",IDLE:"Available Offline",CHECKING:"Checking for Update...",DOWNLOADING:"Downloading Update...",
UPDATEREADY:"Update Ready",OBSOLETE:"Update Failed"};b.addEventListener("load",function(a){for(a in{cached:1,checking:1,downloading:1,error:1,noupdate:1,obsolete:1,progress:1,updateready:1})k.addEventListener(a,g,!1);d(g,0)},!1);e.$on("$routeChangeSuccess",function(a,b,d){a=Date.now();if(6E4<=a-m.time){try{k.update()}catch(e){console.log(e)}m.time=a}})}}])})(g,f);(function(f,c,g){c.run(["$rootScope","$routeParams",function(e,b){e.$on("$routeChangeSuccess",function(a,d,c){e.routePage=d.$$route.pagedata;
e.routeData=d.$$route;e.routeParams=b})}])})(g,f);(function(f,c,g){c.run(["$templateCache","viewHtml",function(e,b){for(var a in b)e.put(a,b[a])}])})(g,f);(function(f,c,g){c.factory("warrStore",["$window","$rootScope",function(e,b){function a(a){try{if(a.setItem("warrStorageTest","warrStorageTest"),"warrStorageTest"==a.getItem("warrStorageTest"))return a.removeItem("warrStorageTest"),{keys:function(){for(var b={},d=0;d<a.length;d++)b[a.key(d)]=!0;return b},get:function(b){return a.getItem(b)},set:function(b,
d){a.setItem(b,d)}}}catch(b){}}function d(a,d){var c=JSON.stringify(a)+":",e=c.length,l={},k=d?f:g,h;for(h in k.keys())if(h.length>=e&&h.substr(0,e)==c)try{l[h.substr(e)]=JSON.parse(k.get(h))}catch(t){}b.$watch(function(){return l},function(){for(var a in l)l.hasOwnProperty(a)&&k.set(c+a,JSON.stringify(l[a]))},!0);return l}var c={},f=a(e.sessionStorage)||{keys:function(){return c},get:function(a){return c[a]},set:function(a,b){c[a]=b}},g=a(e.localStorage)||f,k={},h=f==g?k:{};return function(a,b){var c=
b?k:h;c[a]=c[a]||d(a,b);return c[a]}}])})(g,f)})(h);(function(g,h){var f=g.module("warrData",[]);(function(f,c,g){c.config(["data",function(c){function b(a){for(var c in a){var e=a[c];e instanceof Object&&(e.key&&(e.key=c),b(e))}}b(c)}])})(g,f);(function(f,c,g){c.config(["data",function(c){function b(a){var d=!1,f;for(f in a){var g=a[f],h=g.toString().match(/^\s*\(\((.*)\)\)\s*$/);h&&(a[f]=g=Function("return this."+h[1]).call(c),d=!0);g instanceof Object&&(d=d||b(g))}return d}for(;b(c););}])})(g,
f);f.constant("data",{LICENSE:'Copyright \u00a92015 Aaron Suen\nPortions \u00a92010-2015 Google, Inc.\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ',
pages:{home:{key:"1",name:"Home",order:"1",route:"/",view:"home"},license:{key:"1",name:"License",route:"/license",view:"license"},priorart:{key:"1",name:"Prior Art",order:"4",route:"/priorart",view:"priorart"},priorartdetail:{doc:"((priorart))",key:"1",name:"Prior Art",route:"/priorart/:id",title:"title",view:"priorartdetail"},resume:{key:"1",name:"Experience",order:"2",route:"/resume",view:"resume"},software:{key:"1",name:"Software",order:"3",route:"/software",view:"software"},softwaredetail:{doc:"((software))",
key:"1",name:"Software",route:"/software/:id",title:"name",view:"softwaredetail"}},priorart:{checksumchallenge:{date:"2015-10-13",key:"1",text:["Just for fun, this is an old code-breaking challenge that I've previously posed in a couple of different forms, updated for modern computing power.\nGiven this piece of C# code that's called with a secret value:",{html:"<pre>void Display(string secret) {\n        if(secret.Any(c => (c < '0') || (c > '9')))\n                throw new Exception(\"invalid secret\");\n        Console.WriteLine(secret.Length);\n        uint checksum = 0;\n        foreach(char c in secret)\n                checksum = (uint)(((checksum * 1297) ^ c) & 1048575);\n        Console.WriteLine(checksum);\n        Console.WriteLine(Convert.ToBase64String(SHA256.Create()\n                .ComputeHash(Encoding.ASCII.GetBytes(secret))));\n}</pre>"},
"...it produces this output:",{html:"<pre>12\n216159\ncN3K7MdpE3SfIW8+il9lgwk2dL+YtkYu2ULQ40NQlEQ=</pre>"},"Can you figure out the secret input value?  If you can, please share your method (and your source code) with me.\nMy original solution, written in C#, found the answer in about 50 seconds on a quad-core i7-2600 3.4GHz CPU."],title:"Just for Fun: Checksum Challenge"},featurecaschunking:{date:"2013-08-01",key:"1",links:{epitome:"http://www.peereboom.us/epitome/",git:"http://git-scm.org/"},text:"I store a lot of data in git;  I use it as a form of source control, as well as a backup and file distribution medium, the way some people might use dropbox. Its only weakness is delta compression.\nCompression is basically the removal of redundancies from data; git takes advantage of the fact that the data it stores is fundamentally a series of snapshots by storing exact-duplicate files across its entire history in a single location, addressed by the hash of the file content.  I have seen real-world schemes like this produce compression of as much as 99%, when combined with a simple stream-level compression algorithm like gzip, while still offering very good seekability (you can extract selected files from the archive).\nWhere delta compression comes into play is when potentially dealing with large files that have data that is mostly redundant, but not an exact match of any other file in the archive.  Git compares files that it suspects may be similar, and tries to describe one or more files as binary diffs from another.  If the files are very similar, the diffs will be much smaller than the original files, and can still be extracted with minimal processing.  The problem with delta compression is that it consumes a lot of time and memory, to the point where it may fail on machines that are very restricted in memory capacity, or during operations (such as git pack-upload) that are restricted in time.\nAn alternative approach to dealing with sub-file data redundancies is to split every file into chunks, such as done by Marco Peereboom's epitome, which splits stream data into user-defined fixed-size chunks.  This works well for certain types of binary data that is modified in-place, such as large databases, in which modified records are generally overwritten in-place within the file, for performance.  Where it will not work as well is in files that may only partially change, but are generally rewritten, such as a plain-text file.  If you insert or remove a small amount of text, much of the file remains the same, but when you save it over the old file, unless the amount of text you added or removed exactly matches the chunk size, all of your chunks will be realigned and not match existing chunks in the archive.\nOn October 10, 2011, I set out to find a solution to this problem: one that could afford me compression offered by git with delta-compression to de-duplicate matching pieces of non-matching, non-aligned files, but with epitome's simplicity, performance and low-memory footprint, not requiring any maintenance or re-packing.  What I came up with was splitting the file into chunks of variable, but constrained, size, based on features found within the data itself.\nGiven a file that we want to split into chunks, let V = f(DATA, POS), where DATA is the array of bytes that comprises the file's content stream and POS is an offset within that stream, at each position.  Given user-configured size constraints CHUNK_MIN and CHUNK_MAX, and given an offset POS within the file, which is either the beginning of the file, or the end of the last chunk found, we search for a minimum or maximum value of V between POS + CHUNK_MIN and POS + CHUNK_MAX.  If multiple results are found, we select the one with the highest position (largest chunk). Depending on our selection of the function f(DATA, POS), these window-local minima/maixma will tend to shift when the underlying data shifts, so that even if data is inserted into or removed from the stream, the chunking algorithm will eventually realign with the previous features in new positions.\nFor a proof-of-concept, I used CHUNK_MIN = 32kb, CHUNK_MAX = 64kb, and f(DATA, POS) = the value of a 64-bit little-endian unsigned integer read from offset POS - 7 to POS, where bytes outside of the range of DATA were assumed to be 0.  This choice of function had the advantages of simplicity and speed, and could be computed on-the-fly as bytes were read from the file instead of requiring a second pass; other functions, such as the Alder32 hash used by rsync, may offer similar advantages and may perform better or worse for this purpose.  I searched for a maximum value, rather than a minimum, as I expected that zero-padding in binary files would cause a lot of minima to be found. Metadata was stored within the archive as well: stream chunk lists were serialized to XML and then stored into the archive in chunks (repeated until the final stream fit within a single chunk) and directories were stored serialized into XML as streams as well.\nWhile I had hypothesized that the algorithm would \"correct\" its alignment within a few chunks after a disturbance (modifying, inserting, or removing data), when I tested against a large corpus of plain text files, the algorithm was able to self-correct immediately on the next chunk in nearly all of my testing, and within 2 chunks in every test.  I also tried inserting a corpus of binary files, which were made by compiling different versions of source code within the same project, which had seen significant active development between these versions; I got an 81% hit rate of exactly-matching chunks, even though almost no files exactly matched.  I did not use any chunk-level compression in my tests, though compressing each chunk with an algorithm like gzip would be helpful in a real-world implementation.\nThere are some areas for improvement I have already identified, such as good choices for CHUNK_MIN, CHUNK_MAX, and f(DATA, POS).  There may also be a way to unobtrusively use data already in the archive to help guide chunk boundary selection to better align with existing chunk data.  With further tuning, this system could provide compression and random-access performance comparable to existing archival systems like epitome or git, without any need for re-packing or maintenance.",
title:"Feature-Based File Chunking for Content-Addressable Storage De-Duplication"},pubkeypbkdf:{date:"2013-06-30",key:"1",links:{DHE:"https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange",PBKDF2:"https://en.wikipedia.org/wiki/PBKDF2",PGP:"https://en.wikipedia.org/wiki/Pretty_Good_Privacy",PKI:"https://en.wikipedia.org/wiki/Public-key_infrastructure",RSA:"https://en.wikipedia.org/wiki/RSA_(algorithm)",SSH:"https://en.wikipedia.org/wiki/Secure_Shell","WPA2-PSK":"https://en.wikipedia.org/wiki/Wi-Fi_Protected_Access",
"X.509":"https://en.wikipedia.org/wiki/X.509","rubber hose":"https://en.wikipedia.org/wiki/Rubber-hose_cryptanalysis"},text:'Some time ago (the first source commit to my proof-of-concept project was on July 30, 2009), I was reading up on WPA2-PSK, when I came across the description of PBKDF2.  Up until that point, the concept of using passwords as shared-secret key material had seemed archaic and insecure to me. A general outline of how I had always thought about symmetric keys:\n<ol> <li>Acquire n bits of strong random data for an n-bit key.</li> <li>Use this random value as the key.</li> <li>Exchange or store this key using some private, authenticated exchange system, e.g. PKI or DHE.</li> </ol>\nA general outline of PBKDF systems:\n<ol> <li>Collect password and salt data from user and/or config.</li> <li>Hash password/salt with an n-bit digest algorithm (or a digest truncated to n bits) for an n-bit key.</li> <li>Use key without storing/exchanging, as other parties or sessions needing the same key can derive it independently.</li> </ol>\nI noticed some parallels between my "usual" symmetric key creation pattern and the pattern for public key use, particularly for RSA:\n<ol> <li>Acquire n bits worth of strong random data for an n-bit key.</li> <li>Using this as a starting point, search for appropriate large numbers that satisfy the algorithm\'s key requirements, e.g. for RSA, search for prime numbers.</li> <li>When a valid private key is found, derive the corresponding public key.</li> <li>Distribute the public key.</li> <li>Store the private key, usually encrypted.</li> </ol>\nBased on these, it isn\'t hard to imagine a way to create a process for deriving a public/private key pair from a password/salt:\n<ol> <li>Collect password and salt data from user and/or config.</li> <li>Hash password/salt with an n-bit digest algorithm (or truncate to n bits) for n-bit key.</li> <li>Using this as a starting point, search for appropriate large numbers that satisfy the algorithm\'s key requirements, e.g. for RSA, search for prime numbers.</li> <li>When a valid private key is found, derive the corresponding public key.</li> <li>Distribute the public key.</li> <li>When done with it, destroy the private key, as it can be re-derived from the same password/salt again later.</li> </ol>\nThere are a few details here that may require some attention, such as a method to generate an arbitrary-length message digest; some techniques may distribute the input entropy throughout the digest better or worse than others.  To create a 2048-bit RSA key, simply derive a 2048-bit digest from the input password/salt data, split it into 2 1024-bit integers, and for each one, increment (or decrement) it until it is a prime number.  Select a public modulus (a well-known value like 65537 should suffice) and the rest of the public and private key parameters can be derived as normal.  On modern computers, deriving a suitably-secure private key this way should be possible in a reasonable amount of time (seconds to minutes).\nKeys derived this way are interesting for their potential for plausible deniability, which can help protect against coercive ("rubber hose") attacks.  Because the key is not stored, no permanent evidence needs to exist of the possession of a private key, or the number of private keys any individual user controls.  Using a different password, even with the same salt (e.g. a salt file), will yield a different, but very probably valid, key.  Unlike symmetric keys, public/private key pairs can be used to establish identity, e.g. for PGP, X.509, or SSH use.',
title:"Password-Based Key Derivation Functions for Public-Key Cryptography"},stochasticlockout:{date:"2014-03-30",key:"1",text:'I first came up with this idea in college in the early 2000\'s decade, though the first working implementation I can find is from September 9, 2006.\nIf one provides a mechanism for a remote network user to log in using a password, it creates the possibility that an attacker could use it to crack the password via an online brute-force attack.  The search space for realistic user passwords is so small that this sort of attack is generally practical.\nThe usual mechanism used to prevent this is account lockout, i.e. after some X failed password attempts within T time, the account is disabled and further login attempts are blocked, until some chosen span of time has passed since the lockout began, or the account is manually re-enabled by an administrator.  While this mitigates the risk of the user\'s password being cracked, it creates a new denial of service vulnerability.  Users who are denied service to applications they consider "critical" will often put pressure on the site administrators to repeatedly re-enable their accounts, or reduce or remove the impact of the lockout feature.  This effectively creates an incentive for an attacker to exploit the new denial-of-service vulnerability, to apply pressure to reduce the system\'s security to the original level before account lockout is applied.\nA more optimal system would mitigate the risk of online brute-force cracking, while still ensuring that legitimate users have access to their own accounts.  By treating an accounts "locked out" status not as boolean, but as a probability, we can achieve this, and it also creates the opportunity to remove incentives for an attacker to attempt brute-force password cracking attempts.\nWhenever an incorrect password is supplied for a given account, we save/update a "last password failure" timestamp Tfail.  Then, on each password login attempt, we compute a probability value P from the time difference (Tnow - Tfail) using some chosen function f(Tdiff) (an optimal function may or may not exist, further research here may be warranted).  Regardless of whether the password is correct or not, we return a login failure error (indistinguishable from any other login error such as wrong password or wrong username) with probability P.\nThe actual function I generally use is P = 0 (no false negatives) if Tdiff > Tmax, and P = (Tmax / Tdiff) if 0 < Tdiff < Tmax, for some small (but configurable) Tmax, like 10 seconds. When a user guesses a password wrong, it generally takes them about 10 seconds to re-enter the password and try again.  By that time, P will have fallen back to 0, so a correct password will be accepted immediately.\nIf an attacker attempts an online brute-force attack, then even in the event the attacker guesses the password correctly, a false negative may be generated.  This means that to perform an exhaustive search (i.e. where the search possibilities are actually exhausted) the attacker would have to delay between each attempt by Tmax; there are no benefits to using shorter delays, and the minimum delay is large enough to make an online brute-force attack completely impractical.  Even if the attacker adds the optimal delay, failed login attempts are still not exhaustive, since the last password failure timestamp is global for all login attempts to that account, and somebody else may be generating password failures for the same account at the same time.\nAn attacker is also unable to launch an effective denial-of-service attack against any account, as there is always a non-zero probability that a legitimate user with the correct password will be able to log in.  Most legitimate users will probably assume that they mis-keyed the password, try again, and will be allowed access within a few attempts.  To maintain a high enough probability of access denial to effectively deny access to an account beyond this level would require a significant and continuing investment of network resources from an attacker, and if the user contacts the site administrators, the admins can simply tell the user to keep trying, and the user will still eventually get in.  As soon as the active attack stops, the ability to log into the account will quickly be restored to normal, so there are no long lockout periods to wait out.\nOne subtlety to watch out for is not to try to short-circuit the password hash calculation based on the stochastic false failures.  Doing so could allow an attacker to use the timing side-channel to determine if the failure was a false negative, and thus restore the ability to exhaust search possibilities.  Replacing the password hash with an "equivalent" delay may also not work, as the attacker could measure real CPU consumption through another side-channel (e.g. parallel queries); it\'s important that the stochastic lockout mechanism doesn\'t create alternate paths with measurably different CPU time costs.',
title:"Stochastic Account Lockout"}},resume:{berktek:{desc:"Implemented and maintained software to operate and synchronize communication test equipment.\nDesigned and ran experiments to test gigabit Ethernet and fiber optic communications equipment.",end:"2002-12",key:"1",loc:"New Holland, PA",org:"Berk-Tek, Inc.",start:"2002-05",title:"Engineering Co-op (Internship)"},expoappdev:{desc:"((resume.expoappdevcon.desc))",end:"2006-07",key:"1",loc:"Frederick, MD",org:"Experient, Inc.",start:"2005-09",
title:"Application Developer"},expoappdevcon:{desc:"Delivered software applications with complex or difficult requirements to top strategic clients.;Performed maintenance and improvements to internal Framework and application template software.;Developed a Batch Validation tool that pre-emptively identifies and corrects problems with imported data.;Created an integrated Content Management System to manage text content embedded in existing web applications.;Built trade show, exposition, corporate and association meeting registration applications and web interfaces using C#.NET and ASP.NET.;Developed, and assisted in the development of new software products and improvements to existing products.;Provided technical support to staff in-house and on-site.".split(";"),
end:"2005-09",key:"1",loc:"Frederick, MD",org:"Experient, Inc.",start:"2005-03",title:"Contract Application Developer"},expoappdevsr:{desc:"((resume.expoappdevcon.desc))",end:"2009-06",key:"1",loc:"Frederick, MD",org:"Experient, Inc.",start:"2006-07",title:"Senior Application Developer"},exposoftengr:{desc:"Architected, designed, implemented, documented, and maintained framework, web services, and applications for high-profile products, using C#.NET, WCF, Entity Framework, Microsoft SQL Server, JSON, and XML.\nArchitected, developed, and maintained version control, continuous integration, and an enterprise-wide automated application deployment system.\nDeveloped and provided mentoring for coding patterns and standards, such as exception handling, data access, and web service design conventions.\nDeveloped efficient, responsive web interfaces using C#, ASP.NET, MVC/Razor, jQuery, and HTML5.\nIdentified and corrected performance issues in code and SQL queries, and created systems or patterns to prevent future issues.\nProvided mentoring and advocacy for adoption of Scrum agile process, and assisted with design of Scrum processes in TFS work-order tracking system.\nCoordinated, managed and developed tools to integrate TFS, Visual SourceSafe, and git source control systems.\nProvide guidance and expertise about data encryption, information security, and single sign-on design.",
end:"2013-05",key:"1",loc:"Frederick, MD",org:"Experient, Inc.",start:"2009-06",title:"Software Engineer"},exposoftengrsr:{desc:"((resume.exposoftengr.desc))",key:"1",loc:"Frederick, MD",org:"Experient, Inc.",start:"2013-05",title:"Senior Software Engineer"},psuhddrecovery:{desc:["Recovered data from a damaged Linux dedicated server."],end:"2001",key:"1",loc:"University Park, PA",org:"Pennsylvania State University",start:"2001"},psustudentmentor:{desc:["Answered questions and advised students of an intermediate level C++ programming class.",
"Tutored groups of students in general computer use topics."],end:"2000-05",key:"1",loc:"University Park, PA",org:"Pennsylvania State University",start:"2000-01",title:"Student Mentor"},speitembank:{desc:["Designed, implemented, and maintained test item data bank software for the Institute of Plastics Certification exam."],end:"1996",key:"1",loc:"Brookfield, CT",org:"Society of Plastics Engineers",start:"1996"},systemics:{desc:"Programmed and debugged web CGI applications in C++.\nDeveloped and implemented an online drug database for the Association of Community Cancer Centers (http://www.accc-cancer.org/) on a three-person team.\nDeveloped a symmetric encryption system to protect internal data.",
end:"2000-07",key:"1",loc:"State College, PA",org:"Systemics, Inc.",start:"1999-09",title:"Computer Programmer, C++"}},software:{"1972hosts":{deps:"BSD-style named and dhcpd, nc (netcat)",desc:'1972hosts is a collection of shell scripts which I created to automate the process of configuring a DHCP server and a DNS nameserver between multiple LANs on a VPN. The idea is that the administrator maintains a list of hostnames, IP addresses, and MAC addresses, assigning IP addresses to the hosts as he/she sees fit, based on the routing scheme for the VPN. Then 1972hosts (running 1972d.sh on port 21667 using inetd) keeps the lists synchronized on multiple routers, and configures and restarts dhcpd and named using the host list data and configuration file templates containing the "hostlist" keyword. This software may require some modification to work with your own system.\nThe major shortcoming of the current revision of 1972hosts (aside from poor revision control) is the method of authenticating and distributing the master host list. The administrator must modify the script at a "master" server, and all hosts implicitly trust exactly one other machine (identified by IP address) to serve the master list. Version 2.x is planned to fix these issues using a simpler peer-to-peer UDP network system, PKI to sign host lists, no central point of administration, and delegation of portions of the network to different administrators.',
dev:"OpenBSD, shell scripts",ended:"2003",key:"1",license:"New BSD",links:{src:"1972hosts.tar.gz"},name:"1972hosts",oneline:"DNS/DHCP/VPN host management system (1st generation)",plat:"BSD or similar",started:"2003",status:"Discontinued, Superseded by autohosts"},applaunch:{desc:"A utility for Windows that installs itself and registers itself as an \"applaunch:\" protocol handler.  applaunch: URL's specify the location of a program (e.g. a UNC path on a local network share) to download and launch locally.  Launching programs directly from the network tends to cause locking and performance issues.\nThe folder containing the program is downloaded, recursively, to a local cache path, and run from that path.  There are some optional features, like passing command line args, which are not very well documented.  Each individual must also be confirmed (and optionally whitelisted/blacklisted), as a security feature, to prevent users being susceptible to malicious links for malware installation.\nThis is a spiritual reincarnation of a similar program I wrote for work.  We had a number of utilities deployed to the network, and we were using clunky *.cmd batch scripts to install them locally and run them.  However, the scripts always copied all files unconditionally, making them slow, and they installed files outside of %TEMP%, making us need special tools to automatically clean up that temp space.  The original applaunch protocol handler not only resolved those issues, but also allowed launch links to be shared via a web portal.  The original program's fatal flaw was the lack of security, which the link confirmation in this version resolves.",
dev:"Microsoft Visual Studio .NET",key:"1",license:"ISC",links:{web:"https://gitlab.com/applaunch"},name:"applaunch: Protocol Handler",oneline:"Utility for launching network-shared Windows applications via local cache",plat:"Windows 8",started:"2007",status:"Maintenance Only"},ascacalc:{desc:'ASCACalc and WinWISC are two projects I have completed for Dr. Marley Watkins of the Penn State University Department of Educational and School Psychology and Special Education. Both programs were originally written for the Macintosh (classic) by Dr. Watkins, and I produced (essentially) direct functional ports into a Windows environment (with some obvious changes to the user interface).\nThe programs are intended to help interpreting some childhood behavioral test scores. The test scores are entered into the calculator, and the program will compare the scores with a set of pre-known "profiles" and display information about how well the test case matched the known profiles. This basically is a process called "syndromic profiling" (the validity of which is still fairly controversial).\nASCACalc was the first of the two programs written, and it suffers from some rather obvious user interface deficiencies. WinWISC was written later, and appears to refine the interface a considerable amount (I\'m rather proud of the title bar and caption buttons; this is the first of this type I created). Of course, WinWISC\'s interface is not spectacular by today\'s standards, but I wrote it to work within the limitations of Visual Basic 3 and to be usable on less powerful machines.',
dev:"Microsoft Visual Basic 1",ended:"2000",key:"1",license:'Special ("Shareware")',links:{bin:"ascacalc.zip"},name:"ASCACalc",oneline:"Syndromic profile calculator for Windows",plat:"Windows; Printer optional",started:"2000",status:"Completed"},autohosts:{deps:"BIND 9, ISC dhcpd, Perl w/ IO::KQueue, OpenVPN (optional)",desc:'autohosts is a complete rewrite of 1972hosts (see below) in Perl. The purpose of both projects is to automate configuration of a DHCP server, DNS nameserver, and a "dial-in" VPN server. The script collects network host IP address, hostname, and MAC address information from static text files, DHCP leases, and an OpenVPN connection status file, and delivers these addresses to the DHCP server config and DNS zones in a highly configurable manner.\nThis revision brings a lot of improvements from 1972hosts. The entire application is now housed in a single script, which runs as an event-driven daemon (no longer requiring a cron job or watcher script). All application-specific options are stored in the script (though this may change in later versions), but most of the significant information is stored in the files which are operated upon themselves. Because the script uses intelligent file locking, you can modify the configuration at any time with a text editor, and autohosts will automatically clean up the file.\nI have removed the multiple-LAN features from this version, since I have largely replaced LAN-to-LAN VPN tunnels with a single host-to-LAN star-topology network, thus eliminating my need for this feature.',
dev:"OpenBSD, Perl v5",ended:"2007",key:"1",license:"New BSD",links:{src:"autohosts.tar.gz"},name:"autohosts",oneline:"DNS/DHCP/VPN host management system (2nd generation)",plat:"BSD or similar",started:"2007",status:"Completed (Beta)"},blindpass:{desc:'BlindPass is an experimental, bizarre, insanely secure password safe that trades off even basic usability for enhanced security.  All entries in the database are plausibly deniable; it is not possible to conclusively prove whether or not any entries exist in the database (only an upper bound), and it is not possible to conclusively prove whether or not a given entry exists.\nThis project started when I was listening to an episode of the GRC SecurityNow! podcast in which Gibson was reviewing a collection of password managers for iOS.  At one point, he defined the criteria against which he was evaluating them, and described what he considered to be the ideal security practices for a password safe.  Most of those standards were meant to protect against brute-force attacks to guess the "master password," but I realized that additional security protections were possible, e.g. allowing the system to remain partially secure if partially broken (traditional password safes are generally all or nothing).  I set out to build BlindPass as an academic exercise to see how much security I could add to a password safe, while having just enough usability to be recognizable as a password safe.\nBlindPass is not really usable as a practical security tool.  If you really want this level of security, you would probably be better off abandoning password safes entirely, and deriving your passwords from a strong hash such as scrypt, bcrypt, or PBKDF2.\nThe "perlcli" sub-project is my original proof-of-concept command line project, written in Perl 5.  Among the oddities is the fact that it uses a "snuffle" cipher for symmetric encryption, which avoided the complexities of incorporating a second cryptography dependency, beyond SHA, which was built into the language.\nThe "android" sub-project was the first working end-user-usable prototype with a real graphical UI, and the first application of any significant scale I completed in Android. Some of the built-in cryptographic transforms were improved, e.g. using AES instead of snuffle, and I tried out some UI improvements to make the variable-depth storage concepts and parameters more transparent to the user.\nBlindPass2 is a significant architectural improvement over the previous iterations, along with much better algorithms.  It was built as a single common Java library that could be linked to a command-line UI, a Swing graphical UI, and an Android UI (only the first 2 have been implemented so far).  The algorithms were also hardened to make them "memory-hard" to defeat GPU and ASIC cracking.  The original 2 BlindPass implementations "whitened" the input based on single character frequencies; BlindPass2 used a larger corpus of password statistics, used 2 previous characters of context for statistical whitening, and included intra-record chaff in variable-length records.\nEach sub-project uses completely different algorithms and storage formats, and are completely incompatible with each other.',
dev:"Perl 5, Java (Swing UI, Android SDK)",key:"1",license:"MIT",links:{web:"https://gitlab.com/blindpass/"},name:"BlindPass",oneline:"Proof-of-concept insane-security password safe for multiple platforms",plat:"Mostly Platform-Independent",started:"2012-05-19",status:"Stalled"},bsm1207s:{desc:'BSM1207S stands for "Banks, Suen and Moroski, CSE120 Assignment 7 S-language interpreter," and was written as a project for CSE120 (intermediate computer programming) at Penn State University. The assignment was to write an interpreter for a contrived language called "S" by the instructor, Steve Shaffer.\nThe S language has some quirks (such as a total lack of conditional execution) plus some optional features (such as support for recursive functions, offered as extra credit). BSM1207S supports all features of the original assignment, including recursive execution, plus some features never envisioned by the instructor, including built-in syntax checking and swap-file usage (for recursive programs, since a lack of conditional execution means they must recurse nearly forever, and personal computer had little RAM at the time).',
dev:"GNU g++ or Microsoft Visual C++",ended:"2000",key:"1",license:"New BSD",links:{src:"bsm1207s.tar.gz"},name:"BSM1207S",oneline:"School assignment, interpreter for contrived language",plat:"Any Unix, DOS, or Windows Console",started:"2000",status:"Completed"},bwr:{deps:"Better than Wolves mod for Minecraft",desc:"Better with Renewables was a mod for Better than Wolves, which was a mod for Minecraft that myself and several friends were playing at the time.  The mod was created to address my annoyance that certain resources were not renewable, and further exploration within the game was necessary to maintain a supply.  I didn't much like exploring, preferring to build, so it seemed useful to offer building-oriented solutions to resource supplies, as alternatives to exploration-oriented solutions, without unbalancing the game.\nOne of the significant challenges that this mod addressed was the copyright terms on the upstream components it depended on, which could not be distributed in any form from user to user.  While the makers of Minecraft were fairly lax in this area, allowing the author of Better than Wolves to distribute his code, he himself was very restrictive, so we would not be able to distribute binary builds.\nTo this end, and also because I didn't want to have to force clients to update every time I made a change, I designed my mod-mod to work ONLY server-side, and all game-play decisions were made so that they could be implemented without client-side code.  This also meant that I could distribute it as a patch without including any upstream code, which ended up being acceptable, for the duration of the project, by the upstream authors.  A few dedicated server operators could go through the trouble of getting the components to decompile the game, apply the patches, and recompile, and they could then serve a larger population of players.",
dev:"Java, MCP, Perl 5, Make",ended:"2013-03-26",key:"1",license:"MIT",links:{web:"https://gitlab.com/bwr/"},name:"Better with Renewables",oneline:"Mod for a Minecraft mod that changed game-play server-side",plat:"Mod for Minecraft and Better than Wolves",started:"2012-10-04",status:"Discontinued, Support Ended"},ee486canny:{depends:"libpng",desc:'An early project I did for my EE486 (computer vision) course at Penn State University.\nThis software performs Canny edge detection (a procedure to find edges in an image) on a PNG image and produces another PNG image showing edges in white, plus a text file listing image coordinates of suspected corners, plus a "cornerness" score. The program has a lot of different threshold and blurring value inputs, so it can be difficult to use.',
dev:"OpenBSD, g++",ended:"2004",key:"1",license:"New BSD",links:{src:"canny-edge.tar.gz"},name:"EE486 #2: Canny Edge Detection",oneline:"School assignment, computer vision canny edge detection",plat:"BSD or similar",started:"2004",status:"Completed"},ee486wireframe:{desc:"An early project I did for my EE486 (computer vision) course at Penn State University.\nThis software produces a 3D wireframe image given a text file with 3D coordinates of vertices and segments. I added a sort of anti-aliasing to the program which gives lines a thick look with a soft glow. I chose to output files as PCX images, since this was the only format for which I had ready documentation at the time, and they could be written uncompressed. Unfortunately, uncompressed PCX images are extremely rare and the only software I have seen that supports them is the Gnu Image Manipulation Program (GIMP).",
dev:"OpenBSD, g++",ended:"2004",key:"1",license:"New BSD",links:{src:"wireframe.tar.gz"},name:"EE486 #1: Wireframe",oneline:"School assignment, wireframe render to PCX",plat:"BSD or similar",started:"2004",status:"Completed"},mandelbrot:{desc:"This program was written as one of three programs I presented as my final project for computer science class in my senior year in high school. It's a graphical Mandelbrot fractal browser (using VGA mode 13h in DOS, written in C/C++ plus inline Intel assembly) with 256-color palette rotation effects and 1024x768 bitmap screen capture.",
dev:"Borland C++ v4.5",ended:"1999",key:"1",license:"New BSD",links:{bin:"mandel3-bin.zip",src:"mandel3-src.zip"},name:"Mandelbrot Fractal Viewer",oneline:"Interactive fractal browser for DOS, w/ bitmap export",plat:"DOS (VGA Required)",started:"1999",status:"Completed"},microhex:{desc:"Microhex is a very simplistic and compact hex editor that I wrote in my junior year in high school, in order to modify some binary data for some of my projects, since the school computers did not have hex editors. It can display a small page of data at a time, modify data in hex or ASCII string mode, and even has a primitive search function for case-sensitive text or a string of bytes represented in hex.\nThe executable itself is only about 18k in size and compiled to run on any 80x86 compatible machine, including older ones like the 8086 or 8088. Some of my friends still use this program, more than half a decade later.",
dev:"Turbo Pascal v7.0",ended:"1998",key:"1",license:"New BSD",links:{bin:"microhex.zip"},name:"MicroHex",oneline:"Simple hex editor for DOS",plat:"DOS",started:"1998",status:"Completed"},nucraftd:{deps:"Various Perl modules, depending on features used",desc:"This started out as a watchdog script to keep my notoriously unstable Minecraft server running, restarting it automatically when it crashed. Then, by interacting with the command line console, I started offering in-game time announcements, automated backups, and more.",
dev:"Perl 5",ended:"2014-01-01",key:"1",license:"ISC",links:{web:"https://gitlab.com/nucraftd/"},name:"nucraftd",oneline:"Watchdog and wrapper scripts for Minecraft server",plat:"BSD, GNU/Linux or other Unix-like",started:"2011-01-28",status:"Discontinued"},openbsdsite:{desc:"This is a collection of my personal favorite tweaks and configuration changes to apply to a freshly-installed OpenBSD system.  It once started with a text file with a list of changes, after I had had to perform the same changes across a few installs. It eventually evolved into scripts to automate the patches (instead of diffs so they would be more version-independent).\nIn its current incarnation, rather than a single unified package of changes, the collection has been broken up into a set of independent modules, along with an install-time interface (similar to the OpenBSD textual installer) that allows the user to view the list of changes, view documentation for each (each one has at least SOME documentation), and choose which ones to include/exclude in the installation.",
dev:"Perl 5, sh",key:"1",license:"ISC",links:{web:"https://gitlab.com/Warr1024/openbsdsite/"},name:"OpenBSD Site Mod",oneline:"Packaged collection of install-time tweaks for OpenBSD",plat:"OpenBSD",started:"2007",status:"Ongoing"},proxyrdp:{depends:".NET Framework v1.1",desc:"This is a small .NET Windows application that allows Remote Desktop connections (using the client built into Windows XP, and possibly other versions) through and HTTP proxy using the CONNECT method. I was inspired to write this because of one of the environments in which I work that has only an HTTP proxy to access the outside world, and a pressing need to use remote desktop. A quick internet search for how to get RDP to honor your HTTP proxy settings yielded no useful results, so I wrote this to fill the need.",
dev:"Windows XP, Visual Studio .NET 2003",ended:"2006",key:"1",license:"New BSD",links:{bin:"proxyrdp-bin.zip",src:"proxyrdp-src.zip"},name:"ProxyRDP",oneline:"HTTP proxy for Windows Remote Desktop",plat:"Windows",started:"2006",status:"Completed (Beta)"},szhosts:{deps:"sqlite3 command line",desc:"Yet another successor to 1972hosts and autohosts.  This iteration is much more modular, and monitoring of files is via simple polling of file stats, instead of the overblown kqueue mechanism that, in autohosts, tended to generate a lot of false positives.  Synchronization is achieved via file locking, which is built-in from sqlite.  The command line sqlite3 command is used, instead of a sqlite integration layer for perl, because the command line tool is built into the OpenBSD base system, but the perl module would have required a package install, which may be prohibitive on a lightweight router.",
dev:"OpenBSD, Perl v5",key:"1",license:"ISC",links:{web:"https://gitlab.com/Warr1024/szhosts/"},name:"szhosts",oneline:"DNS/DHCP/VPN host management system (3rd generation)",plat:"BSD or similar",started:"2013-05-30",status:"Ongoing"},website:{deps:"Google Closure Compiler, HTML Tidy",desc:"It was originally redundant to list this website on itself, as its content was the same as its raw source code, but since then, the site has grown some optimizations and automation that require it to be compiled, to produce the final product.",
dev:"OpenBSD, and Debian GNU/Linux, Perl 5, sh",key:"1",license:"MIT",links:{web:"https://gitlab.com/Warr1024/www/"},name:"Aaron Suen Official Website",oneline:"Source code, scripts, and optimizations for this website",plat:"BSD, GNU/Linux, or other Unix-like",started:"2005-03-22",status:"Actively Developed"},winwisc:{desc:'ASCACalc and WinWISC are two projects I have completed for Dr. Marley Watkins of the Penn State University Department of Educational and School Psychology and Special Education. Both programs were originally written for the Macintosh (classic) by Dr. Watkins, and I produced (essentially) direct functional ports into a Windows environment (with some obvious changes to the user interface).\nThe programs are intended to help interpreting some childhood behavioral test scores. The test scores are entered into the calculator, and the program will compare the scores with a set of pre-known "profiles," and display information about how well the test case matched the known profiles. This basically is a process called "syndromic profiling" (the validity of which is still fairly controversial).\nASCACalc was the first of the two programs written, and it suffers from some rather obvious user interface deficiencies. WinWISC was written later, and appears to refine the interface a considerable amount (I\'m rather proud of the title bar and caption buttons; this is the first of this type I created). Of course, WinWISC\'s interface is not spectacular by today\'s standards, but I wrote it to work within the limitations of Visual Basic 3 and to be usable on less powerful machines.',
dev:"Microsoft Visual Basic 3",ended:"2000",key:"1",license:'Special ("Shareware")',links:{bin:"winwisc.zip"},name:"WinWISC",oneline:"Syndromic profile calculator for Windows",plat:"Windows; Printer optional",started:"2000",status:"Completed"}}});f.constant("viewHtml",{daterange:'<div>{{datefmt(start)}} <span data-ng-if= "end &amp;&amp; (start != end)">&#8211; {{datefmt(end)}}</span></div>',home:'<div><h1>Introduction</h1><p>My name is Aaron Suen, and I am an electrical engineer with a strong focus on computer software. I currently work full-time for a trade show registration vendor in Frederick, Maryland, though I may be available for certain kinds of freelance work in addition. Welcome to my web site and professional web portfolio. You will find my resume, software, and other samples of my work.</p><h2>Contact Information</h2><dl> <dt>Email:</dt><dd><a href= "mailto:warr1024%40gmail.com">warr<span>10</span>24@gmail.&#173;com&#173;</a></dd><dt>PGP:</dt> <dd><code><a href="download/pgp-pubkey-334f143f.txt">2182 4D70 03F0 7A65 9809 &#8211; 62C0 604C 43D9 (334F 143F)</a></code></dd><dt>OTR:</dt> <dd><code>E1F3022F 4C32CEED 93686CC0 934F7F98 210C58AE</code></dd></dl></div>',
license:'<div><h1>License</h1><div data-warr-paras="data.LICENSE"></div></div>',priorart:'<div><h1>Prior Art</h1><p>This is a place for my original ideas, musings, and inventions. These ideas are my own, are not covered by any patent known to me or otherwise under the control of any other party (though I make absolutely no warranties). I submit them into the Public Domain to ensure that they remain free. Articles are in reverse order by publication date (newest articles at the top), and follow no specific formal format.</p> <div data-warr-sort-filter-box="\'priorart\'" data-sort-options= "[\'-date\',\'+title\']" data-sort="sort" data-filter="filter"></div><div data-ng-repeat= "pkg in data.priorart | warrValues | filter:filter | orderBy:[sort,\'key\']" class="margins"><h2><a data-ng-href="#/priorart/{{pkg.key}}">{{pkg.title}}</a></h2> <div class="strong" data-warr-date-range="" data-start="pkg.date"></div></div></div>',
priorartdetail:'<div><div data-ng-repeat="pkg in [ data.priorart[routeParams.id] ]"><h2><a data-ng-href="#/priorart">Prior Art</a> &gt; {{pkg.title}}</h2> <div class="strong" data-warr-date-range="" data-start="pkg.date"></div><div data-warr-paras="pkg.text"></div></div></div>',resume:'<div><h1>Professional Experience</h1><div data-warr-sort-filter-box="\'resume\'" data-sort-options= "[\'-start\',\'-end\',\'+org\',\'+title\']" data-sort="sort" data-filter= "filter"></div><div data-ng-repeat= "pkg in data.resume | warrValues | filter:filter | orderBy:[sort,\'-start\',\'key\'] | warrLinkUp"><div data-ng-if="!pkg.prev() || (pkg.prev().org != pkg.org)"> <h2>{{pkg.org}}</h2><div>{{pkg.loc}}</div><br /></div><div class="strong" data-ng-if="pkg.title">{{pkg.title}}</div> <div data-warr-date-range="" data-start="pkg.start" data-end= "pkg.end || \'Present\'"></div><ul data-ng-if="!pkg.next() || (pkg.next().desc != pkg.desc)" data-warr-paras="pkg.desc" data-tag="\'li\'"></ul></div></div>',
software:'<div><h1>Software</h1><p>Over the years, I have written a fairly large amount of computer software, mostly for my own use. I have included here a handful of selected works which I hope you will find useful or interesting. Software is in approximate chronological order, with more recent works at the top of the page.</p><p>I apologize for the horrible (or utterly absent) state of documentation for many of these programming projects. At the time many of these were written, documentation was not a high priority. Many do have built-in help, or what I considered at the time to be an intuitive interface. I have also attempted to include source code for each software package, except where I cannot due to licensing restrictions or loss of the original source code.</p> <p>Each software package contains a file called "license.txt" which contains the software license for that package.</p> <div data-warr-sort-filter-box="\'software\'" data-sort-options= "[\'-started\',\'-ended\',\'+name\']" data-sort="sort" data-filter= "filter"></div> <div data-ng-repeat= "pkg in data.software | warrValues | filter:filter | orderBy:[sort,\'name\',\'key\']"><span class="dltag" data-ng-repeat= "t in [\'web\', \'src\', \'bin\']">{{(pkg.links &amp;&amp; pkg.links[t]) ? t : "-"}}</span><h2><a data-ng-href= "{{\'#/software/\'+pkg.key}}">{{pkg.name}}</a></h2> <div>{{pkg.oneline}}</div><div class="clear" data-warr-date-range="" data-start="pkg.started" data-end="pkg.ended || \'Ongoing\'">&#160;</div></div></div>',
softwaredetail:'<div><div data-ng-repeat="pkg in [ data.software[routeParams.id]]"><h2><a data-ng-href="#/software">Software</a> &gt; {{pkg.name}}</h2> <div>{{pkg.oneline}}</div><dl><dt>Target Platform:</dt><dd>{{pkg.plat}}</dd><dt>Dev Platform:</dt><dd>{{pkg.dev}}</dd><dt>Dependencies:</dt> <dd>{{pkg.deps || "None"}}</dd><dt>License:</dt><dd>{{pkg.license}}</dd><dt>Status:</dt><dd>{{pkg.status}}</dd><dt>Date:</dt> <dd data-warr-date-range="" data-start="pkg.started" data-end= "pkg.ended || \'Ongoing\'">&#160;</dd></dl><dl data-ng-if="pkg.links"> <dt data-ng-if="pkg.links.web">Project Website:</dt><dd data-ng-if="pkg.links.web"><a class="breakall" data-ng-href= "{{pkg.links.web}}">{{pkg.links.web}}</a></dd><dt data-ng-if="pkg.links.bin">Binaries:</dt><dd data-ng-if="pkg.links.bin"><a class="breakall" data-ng-href= "download/{{pkg.links.bin}}">{{pkg.links.bin}}</a></dd><dt data-ng-if="pkg.links.src">Source Code:</dt> <dd data-ng-if="pkg.links.src"><a class="breakall" data-ng-href= "download/{{pkg.links.src}}">{{pkg.links.src}}</a></dd></dl> <div class="c1" data-warr-paras="pkg.desc"></div></div></div>',
sortfilterbox:'<ul class="filter bar"><li><select data-ng-model="store.sort" data-warr-default= "sortOptions[0].i" data-ng-options= "x.i as x.n for x in sortOptions"> <option>dummy</option></select></li><li><input type="text" placeholder="Filter" data-ng-model= "store.filter" /> <input type="submit" value="X" data-ng-click= "store.filter=\'\'" /></li></ul>'})})(h)})(angular);
